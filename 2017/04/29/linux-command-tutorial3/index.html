<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="linux命令学习笔记3 文本处理"><meta name="keywords" content="linux,ubuntu"><meta name="author" content="SizheRee"><meta name="copyright" content="SizheRee"><title>linux命令学习笔记3 文本处理 | SizheRee's Blog</title><link rel="shortcut icon" href="/iamges/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-147407743-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#第三章-文本处理"><span class="toc-number">1.</span> <span class="toc-text">第三章 文本处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-find-文件查找"><span class="toc-number">1.1.</span> <span class="toc-text">3.1 find 文件查找</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-grep-文本搜索"><span class="toc-number">1.2.</span> <span class="toc-text">3.2 grep 文本搜索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-xargs命令行参数转换"><span class="toc-number">1.3.</span> <span class="toc-text">3.3 xargs命令行参数转换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-sort排序"><span class="toc-number">1.4.</span> <span class="toc-text">3.4 sort排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5-uniq消除重复行"><span class="toc-number">1.5.</span> <span class="toc-text">3.5 uniq消除重复行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-6-用tr进行转换"><span class="toc-number">1.6.</span> <span class="toc-text">3.6 用tr进行转换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-7-cut按行切分文本"><span class="toc-number">1.7.</span> <span class="toc-text">3.7 cut按行切分文本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-8-paste-按列拼接文本"><span class="toc-number">1.8.</span> <span class="toc-text">3.8 paste 按列拼接文本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-9-wc-统计行的字符的工具"><span class="toc-number">1.9.</span> <span class="toc-text">3.9 wc 统计行的字符的工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-10-sed文本替换利器"><span class="toc-number">1.10.</span> <span class="toc-text">3.10 sed文本替换利器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-11-awk数据流处理工具"><span class="toc-number">1.11.</span> <span class="toc-text">3.11 awk数据流处理工具</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/images/cat.jpg"></div><div class="author-info__name text-center">SizheRee</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/SizheRee">Github</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">5</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">3</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">4</span></a></div></div></div><div id="content-outer"><div class="plain" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">SizheRee's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div></div><div class="layout" id="content-inner"><article id="post"><div class="plain" id="post-title">linux命令学习笔记3 文本处理</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2017-04-29</time><span class="post-meta__separator">|</span><i class="fa fa-inbox" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/linux/"> linux</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/linux/command/"> command</a></div><div class="article-container" id="post-content"><h1 id="第三章-文本处理"><a href="#第三章-文本处理" class="headerlink" title="第三章 文本处理"></a>第三章 文本处理</h1><p><strong>本节介绍linux下使用Shell处理文本时最常用的工具： find， grep， xargs， sort， uniq， tr， cut， paste， wc， sed， awk；提供的例子和参数都是常用的；我对shell脚本使用的原则是命令单行书写，尽量不要超过2行；如果有更为复杂的任务需求，还是考虑使用python吧。（逃）</strong></p>
<h2 id="3-1-find-文件查找"><a href="#3-1-find-文件查找" class="headerlink" title="3.1 find 文件查找"></a>3.1 find 文件查找</h2><ul>
<li>find的格式<pre><code>find [path...] [expression]
expression = [Options] [Tests] [Actions]组成
find会查找path下的每一个文件，将其带入expression运算的出真值，值为真则执行指定的动作，否则则不执行。</code></pre></li>
<li>find的主要选项<pre><code>$ find . -name pattern 
//将路径前面的目录名去掉后做匹配
$ find . -path pattern
//保留路径名做匹配
$ find . -mmin n
//对文件数据的修改是在n分钟之前的文件
$ find . -mtime n
//对文件数据的修改是在n*24小时之前的文件
$ find . -perm mode
文件的权限位恰好是mode
$ find . -regex pattern
//对整个路径名做正则匹配
$ find . -type c
//文件是c类型的 类型主要有（d 目录| f 普通文件| l 符号链接）</code></pre></li>
<li>组合应用<pre><code>//找出当前目录下的.txt或者.pdf后缀形式的文件并输出文件大小(利用-printf参数你甚至可以自己写一个ls命令)
$ find .\( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \) -printf &apos;%f\t%k\n&apos;
//正则方式查找.txt和.pdf(要注意转义符号的应用)
$ find . -regex &quot;.*\(\.txt\|\.pdf\)$&quot;
// 否定参数，查找锁哟非txt文本：
$ find . ! -name &quot;*.txt&quot; -print
// 忽略大小写的查找,可查找test.c和Test.c
$ find . -iname &quot;test.c&quot;
指定搜索深度，打印出当前目录的文件（深度为1）
$ find . maxdepth 1 -type f</code></pre></li>
<li>定制搜索<pre><code>//按类型搜索,只列出所有目录
$ find . -type d
//按时间搜索，一天前访问过的的文件
$ find . -atime 1
//最近7天访问过的所有文件
$ find . -atime -7 type f -print
//按文件大小搜索
$ find . -type f -size +2k
//查找具有可执行权限的所有文件
$ find . -type f -perm 644 -print
//查找用户lsz所拥有的文件
$ find . -type f -user weber -print</code></pre></li>
<li>对匹配到的文件做后续处理<pre><code>//删除当前目录下所有的swap文件
$ find . -type f -name &quot;*.swap&quot; -delete
//另一种语法
$ find . -type f -name &quot;*.swap&quot; | xargs rm
//使用强大的-exec将当前目录下的所有权变更为lsz（{}会将匹配到的文件替换掉）
$ find . -type f -user root -exec chown lsz {} \;
//将找到的文件copy到另一个目录
$ find . -type f -mtime +10 -name &quot;*.txt&quot; -exec cp {} OLD \;
//如果需要后续执行多个命令，可以将多个命令写成一个脚本。然后-exec执行脚本即可
$ find . -type f -mtime +10 -name &quot;*.txt&quot; -exec ./commands.sh {} ;
//默认使用’\n‘为文件的定界符</code></pre></li>
</ul>
<hr>
<h2 id="3-2-grep-文本搜索"><a href="#3-2-grep-文本搜索" class="headerlink" title="3.2 grep 文本搜索"></a>3.2 grep 文本搜索</h2><ul>
<li><p>简述<br>  Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。使用grep对于?, +, |, {, (, )需要用\转义，而egrep可直接使用。</p>
</li>
<li><p>使用格式</p>
<pre><code>grep [options] PATTERN [FILE]</code></pre></li>
<li><p>主要选项</p>
<pre><code>－c：只输出匹配行的计数。
－I：不区分大 小写(只适用于单字符)。
－h：查询多文件时不显示文件名。
－l：查询多文件时只输出包含匹配字符的文件名。
－n：显示匹配行及 行号。
－s：不显示不存在或无匹配文本的错误信息。
－v：显示不包含匹配文本的所有行。
pattern正则表达式主要参数：
\： 忽略正则表达式中特殊字符的原有含义。
^：匹配正则表达式的开始行。
$: 匹配正则表达式的结束行。
\&lt;：从匹配正则表达 式的行开始。
\&gt;：到匹配正则表达式的行结束。
[ ]：单个字符，如[A]即A符合要求 。
[ - ]：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。
。：所有的单个字符。
* ：有字符，长度可以为0。</code></pre></li>
<li><p>使用简单实例</p>
<pre><code>//以test开头的所有文件为搜索范围，匹配’python‘字符
$ egrep &apos;python&apos; test*
//在多级目录中对文本递归搜索
$ grep &quot;class&quot; . -R -n
//匹配多个模式
$ grep -e &apos;class&apos; -e &apos;vitural; file
//显示至少包含5个连续小写字母的行
$ egrep &apos;[a-z]{5,}&apos; test
//如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符(.*)，这些字符后面紧跟着 另外一个es(\1)，找到就显示该行。如果用egrep或grep -E，就不用”\”号进行转义，直接写成’w(es)t.*\1′就可以了。
$ egrep &apos;w(es)t.*\1&apos; file</code></pre></li>
<li><p>使用复杂实例</p>
<pre><code>//假设您正在’/usr/src/Linux/Doc’目录下搜索带字符 串’magic’的文件
//需要递归查找所有的文件
$ egrep -r magic &apos;./&apos;
//只查找当前目录,并且转到less阅读
$ egrep -d skip magic ./* | less&apos;
//将日志中的带有所有where条件的sql查找出来
$ cat LOG.* | tr a-z A-Z|grep &quot;FROM&quot; | grep &quot;WHERE&quot; &gt; b
//中文查找示例，如果要查找的文字是’中文‘查找到他的utf-8编码和gb2312编码分别是 E4B8ADE69687和D6D0CEC4
$ grep -P &apos;\xE4\xB8\xAD\xE6\x96\x87|\xD6\xD0\CE\xC4&apos; ./*</code></pre></li>
<li><p>下面还有一些有意思的命令行参数：</p>
<pre><code>grep -i pattern files ：不区分大小写地搜索。默认情况区分大小写，
grep -l pattern files ：只列出匹配的文件名，
grep -L pattern files ：列出不匹配的文件名，
grep -w pattern files ：只匹配整个单词，而不是字符串的一部分(如匹配’magic’，而不是’magical’)，
grep -C number pattern files ：匹配的上下文分别显示[number]行，
grep pattern1 | pattern2 files ：显示匹配 pattern1 或 pattern2 的行，
grep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。
grep -n pattern files  即可显示行号信息
grep -c pattern files  即可查找总行数</code></pre></li>
<li><p>这里还有些用于搜索的特殊符号：</p>
<pre><code>\&lt; 和 \&gt; 分别标注单词的开始与结尾。
例如：
grep man * 会匹配 ‘Batman’、’manic’、’man’等，
grep ‘\&lt;man’ * 匹配’manic’和’man’，但不是’Batman’，
grep ‘\&lt;man\&gt;’ 只匹配’man’，而不是’Batman’或’manic’等其他的字符串。
‘^’：指匹配的字符串在行首，
‘$’：指匹配的字符串在行 尾，</code></pre></li>
</ul>
<hr>
<h2 id="3-3-xargs命令行参数转换"><a href="#3-3-xargs命令行参数转换" class="headerlink" title="3.3 xargs命令行参数转换"></a>3.3 xargs命令行参数转换</h2><ul>
<li>简述<br>  xargs命令是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具。它擅长将标准输入数据转换成命令行参数，xargs能够处理管道或者stdin并将其转换成特定命令的命令参数。xargs也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。xargs的默认命令是echo，空格是默认定界符。这意味着通过管道传递给xargs的输入将会包含换行和空白，不过通过xargs的处理，换行和空白将被空格取代。xargs是构建单行*命令的重要组件之一。</li>
<li>用法<pre><code>xargs [options] [command]</code></pre></li>
<li>重要选项<pre><code>-d 定义定界符
-n 指定输出为多行
-I {} 指定替换字符串， 这个字符串会在xargs拓展时被替换掉，用于待执行命令需要多个参数时
-0 指定null（0）为输入定界符，与find的print0可串联使用</code></pre></li>
<li>简单实例<pre><code>//将多行输出转化为单行输出
$ cat file.txt | xargs
   //将单行转化为多行 以每行3个字段显示
$ cat file.txt | xargs -n 3
//统计程序行数
$ cat file.txt | xargs -I {} ./command.sh -p {} -1
//计算所有的文件的行数（有些相当与python里面的map)
$ find ./ -name &apos;*test[AB].c&apos;  | sort| xargs  -I {} wc -l {}</code></pre></li>
</ul>
<hr>
<h2 id="3-4-sort排序"><a href="#3-4-sort排序" class="headerlink" title="3.4 sort排序"></a>3.4 sort排序</h2><ul>
<li>简述<br>  sort命令是在Linux里非常有用，它将文件进行排序，并将排序结果标准输出。sort命令既可以从特定的文件，也可以从stdin中获取输入。</li>
<li>语法<pre><code>sort [Option]... [File]...</code></pre></li>
<li>重要选项<br>  -b：忽略每行前面开始出的空格字符；<br>  -c：检查文件是否已经按照顺序排序；<br>  -d：排序时，处理英文字母、数字及空格字符外，忽略其他的字符；<br>  -f：排序时，将小写字母视为大写字母；<br>  -i：排序时，除了040至176之间的ASCII字符外，忽略其他的字符；<br>  -m：将几个排序号的文件进行合并；<br>  -M：将前面3个字母依照月份的缩写进行排序；<br>  -n：依照数值的大小排序；<br>  -o&lt;输出文件&gt;：将排序后的结果存入制定的文件；<br>  -r：以相反的顺序来排序；<br>  -t&lt;分隔字符&gt;：指定排序时所用的栏位分隔字符；<br>  +&lt;起始栏位&gt;-&lt;结束栏位&gt;：以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。</li>
<li>简单实例<pre><code>cat sort.txt ;printf &apos;*********\n&apos;; sort sort.txt
aaa:10:1.1
ccc:30:3.3
ddd:40:4.4
bbb:20:2.2
eee:50:5.5
eee:50:5.5
*********
aaa:10:1.1
bbb:20:2.2
ccc:30:3.3
ddd:40:4.4
eee:50:5.5
eee:50:5.5
//忽略相同行
$ cat -u sort.txt
aaa:10:1.1
bbb:20:2.2
ccc:30:3.3
ddd:40:4.4
eee:50:5.5
//使用 -n -r -k -t
$ cat sort.txt
AAA:BB:CC
aaa:30:1.6
ccc:50:3.3
ddd:20:4.2
bbb:10:2.5
eee:40:5.4
eee:60:5.1
// 按字符串数值比较大小（ASCII码）
$ sort sort.txt -n
// 按照BB列的数字大小排序
$ sort -nrk 2 -t: sort.txt
eee:60:5.1
ccc:50:3.3
eee:40:5.4
aaa:30:1.6
ddd:20:4.2
bbb:10:2.5
AAA:BB:CC</code></pre></li>
<li>-k 复杂用法实例<br>  -k选项的语法格式：<br>  FStart.CStart<br>  Modifie,FEnd.CEnd Modifier<br>  ——-Start——–,——-End——–<br>  FStart.CStart 选项 , FEnd.CEnd<br>  选项<br>  这个语法格式可以被其中的逗号,分为两大部分，Start部分和End部分。Start部分也由三部分组成，其中的Modifier部分就是我们之前说过的类似n和r的选项部分。我们重点说说Start部分的FStart和C.Start。C.Start也是可以省略的，省略的话就表示从本域的开头部分开始。FStart.CStart，其中FStart就是表示使用的域，而CStart则表示在FStart域中从第几个字符开始算“排序首字符”。同理，在End部分中，你可以设定FEnd.CEnd，如果你省略.CEnd，则表示结尾到“域尾”，即本域的最后一个字符。或者，如果你将CEnd设定为0(零)，也是表示结尾到“域尾”。<br>  从公司英文名称的第二个字母开始进行排序：<pre><code>$ sort -t -k 1.2 facebook.txt
baidu 100 5000
sohu 100 4500
google 110 5000
guge 50 3000</code></pre>  使用了-k 1.2，表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序。你会发现baidu因为第二个字母是a而名列榜首。sohu和 google第二个字符都是o，但sohu的h在google的o前面，所以两者分别排在第二和第三。guge只能屈居第四了。<br>  只针对公司英文名称的第二个字母进行排序，如果相同的按照员工工资进行降序排序：<pre><code>$ sort -t -k 1.2,1.2 -nrk 3,3 facebook.txt
baidu 100 5000
google 110 5000
sohu 100 4500
guge 50 3000</code></pre>  由于只对第二个字母进行排序，所以我们使用了-k 1.2,1.2的表示方式，表示我们“只”对第二个字母进行排序。（如果你问“我使用-k 1.2怎么不行？”，当然不行，因为你省略了End部分，这就意味着你将对从第二个字母起到本域最后一个字符为止的字符串进行排序）。对于员工工资进行排序，我们也使用了-k 3,3，这是最准确的表述，表示我们“只”对本域进行排序，因为如果你省略了后面的3，就变成了我们“对第3个域开始到最后一个域位置的内容进行排序”了。</li>
</ul>
<hr>
<h2 id="3-5-uniq消除重复行"><a href="#3-5-uniq消除重复行" class="headerlink" title="3.5 uniq消除重复行"></a>3.5 uniq消除重复行</h2><ul>
<li>简述<br>  文本中的重复行，基本上不是我们所要的，所以就要去除掉。linux下有其他命令可以去除重复行，但是我觉得uniq还是比较方便的一个。使用uniq的时候要注意以下二点<br>  1，对文本操作时，它一般会和sort命令进行组合使用，因为uniq 不会检查重复的行，除非它们是相邻的行。如果您想先对输入排序，使用sort -u。<br>  2，对文本操作时，若域中为先空字符(通常包括空格以及制表符)，然后非空字符，域中字符前的空字符将被跳过</li>
<li>语法<pre><code>uniq [Option] [Input[Output]]</code></pre></li>
<li>主要参数<pre><code>-c, --count              //在每行前加上表示相应行目出现次数的前缀编号
-d, --repeated          //只输出重复的行
-D, --all-repeated      //只输出重复的行，不过有几行输出几行
-f, --skip-fields=N     //-f 忽略的段数，-f 1 忽略第一段
-i, --ignore-case       //不区分大小写
-s, --skip-chars=N      //根-f有点像，不过-s是忽略，后面多少个字符 -s 5就忽略后面5个字符
-u, --unique            //去除重复的后，全部显示出来，根mysql的distinct功能上有点像
-z, --zero-terminated   end lines with 0 byte, not newline
-w, --check-chars=N      //对每行第N 个字符以后的内容不作对照
--help              //显示此帮助信息并退出
--version              //显示版本信息并退出</code></pre></li>
<li>主要用法<pre><code>//统计各行在文件中出现的次数
   sort unsort.txt | uniq -c
//找出重复行
sort unsort.txt | uniq -d</code></pre></li>
</ul>
<hr>
<h2 id="3-6-用tr进行转换"><a href="#3-6-用tr进行转换" class="headerlink" title="3.6 用tr进行转换"></a>3.6 用tr进行转换</h2><ul>
<li>简述<br>  tr用来从标准输入中通过替换或删除操作进行字符转换。tr主要用于删除文件中控制字符或进行字符转换。使用tr时要转换两个字符串：字符串1用于查询，字符串2用于处理各种转换。tr刚执行时，字符串1中的字符被映射到字符串2中的字符，然后转换操作开始。</li>
<li>用法<pre><code>tr [Option]... SET1 [SET2]
//tr -c -d -s [&quot;string1_to_translate_from&quot;][&quot;string2_to_translate_to&quot;] &lt; input-file</code></pre></li>
<li>主要选项<pre><code>-c 用字符串1中字符集的补集替换此字符集，要求字符集为ASCII。
-d 删除字符串1中所有输入字符。
-s 删除所有重复出现字符序列，只保留第一个；即将重复出现字符串压缩为一个字符串。</code></pre></li>
<li>字符范围<pre><code>指定字符串1或字符串2的内容时，只能使用单字符或字符串范围或列表。
[a-z] a-z内的字符组成的字符串。
[A-Z] A-Z内的字符组成的字符串。
[0-9] 数字串。
\octal 一个三位的八进制数，对应有效的ASCII字符。
[O*n] 表示字符O重复出现指定次数n。因此[O*2]匹配OO的字符串。
tr中特定控制字符的不同表达方式
速记符含义八进制方式
\a Ctrl-G  铃声\007
\b Ctrl-H  退格符\010
\f Ctrl-L  走行换页\014
\n Ctrl-J  新行\012
\r Ctrl-M  回车\015
\t Ctrl-I  tab键\011
\v Ctrl-X  \030</code></pre></li>
<li>应用实例<pre><code>//将文件file中的出现的&apos;a&apos; &apos;b&apos; &apos;c&apos;换为&apos;x&apos; &apos;y&apos; &apos;z&apos;
$ cat file | tr &apos;abc&apos; &apos;xyz&apos; &gt; new_file
//使用tr命令统一大小写
$ cat file | tr [a-z] [A-Z] &gt; file
$ cat file | tr [A-Z] [a-z] &gt; file
 //删除文件中的snail字符【注意】这里，凡是在file文件中出现的&apos;S&apos;,&apos;n&apos;,&apos;a&apos;,&apos;i&apos;,&apos;l&apos;字符都会被删除！而不是紧紧删除出现的&quot;Snail”字符串。
$ cat file | tr -d &apos;snail&apos; &gt; file
   //删除文件file中出现的换行&apos;\n&apos;、制表&apos;\t&apos;字符
$ cat file | tr -d &quot;\n\t&quot; &gt; newfile
//删除“连续着的”重复字母，只保留第一个
$ cat file  | tr -s [a-z][A-Z] &gt; newfile
   删除空行
$ cat file | tr -s &quot;\n&quot; &gt; new_file
//删除Windows文件“造成”的&apos;^M&apos;字符
$ cat file | tr -d &quot;\r&quot; &gt; new_file
$ cat file | tr -s &quot;\r&quot; &quot;\n&quot; &gt; new_file</code></pre></li>
</ul>
<hr>
<h2 id="3-7-cut按行切分文本"><a href="#3-7-cut按行切分文本" class="headerlink" title="3.7 cut按行切分文本"></a>3.7 cut按行切分文本</h2><ul>
<li>简述<br>  cut是一个选取命令，就是将一段数据经过分析，取出我们想要的。一般来说，选取信息通常是针对“行”来进行分析的，并不是整篇信息分析的。在 每个文件FILE的各列中,把提取的片断显示在标准输出.</li>
<li>用法<pre><code>cut [Option]... [File]...</code></pre></li>
<li>主要参数<pre><code>-b, --bytes=LIST
      输出 这些 字节, 以字节定位
-c, --characters=LIST
      输出 这些 字符， 以字符定位
-d, --delimiter=DELIM
      使用 DELIM 取代 TAB 做 字段(field) 分隔符
-f, --fields=LIST
      输出 这些 字段， 以字段定位
-s, --only-delimited
     不显示 没有 分隔符 的 行
--output-delimiter=STRING
      使用 STRING 作为 输出分隔符, 缺省 (的 输出分隔符) 为 输入分隔符
LIST:
N      第 N 个 字节, 字符 或 字段, 从 1 计数 起
N-     从 第 N 个 字节, 字符 或 字段 直至 行尾
N-M    从 第 N 到 第 M (并包括 第M) 个 字节, 字符 或 字段
-M     从 第 1 到 第 M (并包括 第M) 个 字节, 字符 或 字段
如果 没有 指定 文件 FILE, 或 FILE 是 -, 就从 标准输入 读取 数据.</code></pre></li>
<li>简单用法<pre><code>//截取who命令的第1-3个字节和第8个字节
$ who | cut -b 1-3，8
//提取每列的第1，3，9-15，个字符
$ who | cut -c 1,3,9-15
//对于非标准形式排列的文件，我们可以人为规定字段做切割
//比如以冒号做切割得到文件的第1，3列
$ cut -d &apos;:&apos; -f 1,3 /etc/password
//显示文件除了第3列之外的所有列
$ cut -f 3 --complement filename</code></pre></li>
</ul>
<hr>
<h2 id="3-8-paste-按列拼接文本"><a href="#3-8-paste-按列拼接文本" class="headerlink" title="3.8 paste 按列拼接文本"></a>3.8 paste 按列拼接文本</h2><ul>
<li>简述<br>  连续 依次 从 各个 文件 FILE 中 读取 一列 然后 合并成 新列, 中间 用 TAB 隔开, 新行 写到 标准输出.  如果 文件 FILE 不存在, 或者 FILE 是 ‘-‘, 就从 标准输入 读取 数据.</li>
<li>用法<pre><code>paste [Option].. [File]...</code></pre></li>
<li>主要参数<pre><code>-d, --delimiters=LIST
      循环使用 LIST 中 的 字符 取代 TAB
  -s, --serial
      一次 粘贴 一个 文件, 而不是 并行 粘贴</code></pre></li>
<li>简单实例<pre><code>//将file1和file2用逗号连接在一起
$ paste file1 file2 -d &apos;,&apos;
//串行粘贴
$ paste file1 file2 -s</code></pre></li>
</ul>
<hr>
<h2 id="3-9-wc-统计行的字符的工具"><a href="#3-9-wc-统计行的字符的工具" class="headerlink" title="3.9 wc 统计行的字符的工具"></a>3.9 wc 统计行的字符的工具</h2><ul>
<li>简述<br>  对每个文件输出行、单词、和字节统计数，如果指定了多于一个文件则还有一 个行数的总计。没有指定文件或指定的文件是 -，则读取标准输入。</li>
<li>用法<pre><code>wc [Option]... [File]...</code></pre></li>
<li>主要参数<pre><code>-c, --bytes, --chars
       输出字节统计数。
-l, --lines
       输出换行符统计数。
-L, --max-line-length
       输出最长的行的长度。
-w, --words
       输出单词统计数。</code></pre></li>
<li>简单实例<pre><code>//统计行数
$ wc -l file
//统计单词数
$ wc -w file
//统计字符数
$ wc -c file</code></pre></li>
</ul>
<hr>
<h2 id="3-10-sed文本替换利器"><a href="#3-10-sed文本替换利器" class="headerlink" title="3.10 sed文本替换利器"></a>3.10 sed文本替换利器</h2><ul>
<li><p>简述<br>  sed 是一种文件流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。</p>
</li>
<li><p>用法</p>
<pre><code>sed [OPTION]... {script-only-if-no-other-script} [input-file]...</code></pre></li>
<li><p>主要参数</p>
<pre><code>-n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。
-e ：直接在命令列模式上进行 sed 的动作编辑；
-f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；
-r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)
-i ：直接修改读取的文件内容，而不是输出到终端。
动作说明： [n1[,n2]]function
n1, n2 ：不见得会存在，一般代表『选择进行动作的行数』，举例来说，如果我的动作是需要在 10 到 20 行之间进行的，则『 10,20[动作行为] 』

function：
a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～
c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！
d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；
i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；
p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～
s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！</code></pre></li>
<li><p>简单实例</p>
<pre><code>//将 /etc/passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除！
$ nl /etc/passwd | sed &apos;2,5d&apos;
//在第2行后添加hello world
$ nl /etc/passwd | sed &apos;2a hellow world&apos;
//在第2行前添加hello world
$ nl /etc/passwd | sed &apos;2i hellow world&apos;
   //将第2-5行替换为hello world
$ nl /etc/passwd | sed &apos;2,5c hellow world&apos;
// 仅列出2-7行
$ nl /etc/passwd | sed -n &apos;2,7p&apos;
//搜索/etc/passwd有root关键字的行，使用-n只打印包含模板的行
$ nl -n /etc/passwd | sed &apos;/root/p&apos;
//删除/etc/passwd所有包含root的行
$ nl /etc/passwd | sed &apos;/root/d&apos;
//数据的搜寻并执行命令
nl /etc/passwd | sed -n &apos;/root/{s/bash/blueshell/;p}&apos;
//如果只替换/etc/passwd的第一个bash关键字为blueshell，就退出
$ nl /etc/passwd | sed -n &apos;/bash/{s/bash/blueshell/;p;q}&apos;
//移除空白行
$ sed &apos;/^$/d&apos; file
//第一个匹配的括号内容使用标记1来引用
$ nl /etc/passwd | sed -n &apos;s/hello\([0-9]\)/\1&apos;
//使用双引号求职
 $ sed &apos;s/$var/HLLOE/&apos;
//字符串插入字符/，将文本中的每行内容（ABCDEF）转换为ABC/DEF
$ sed &apos;s/^.\{3\}/&amp;\//g&apos; file</code></pre></li>
</ul>
<hr>
<h2 id="3-11-awk数据流处理工具"><a href="#3-11-awk数据流处理工具" class="headerlink" title="3.11 awk数据流处理工具"></a>3.11 awk数据流处理工具</h2><ul>
<li>简介<br>  awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。</li>
<li>用法<br>  mawk [-W option] [-F value] [-v var=value] [–] ‘program text’ [file …]<br>  mawk [-W option] [-F value] [-v var=value] [-f program-file] [–] [file …]</li>
</ul>
<p>$$<br>  \begin{matrix}<br>   1 &amp; 2 &amp; 3 \<br>   4 &amp; 5 &amp; 6 \<br>   7 &amp; 8 &amp; 9<br>  \end{matrix} \tag{1}<br>$$</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">SizheRee</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://sizheree.github.io/2017/04/29/linux-command-tutorial3/">http://sizheree.github.io/2017/04/29/linux-command-tutorial3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://sizheree.github.io">SizheRee's Blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/linux/">linux</a><a class="post-meta__tags" href="/tags/ubuntu/">ubuntu</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/images/alipay.jpg"><div class="post-qr-code__desc">支付宝打赏</div></div></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/09/08/认知迭代/"><i class="fa fa-chevron-left">  </i><span>&lt;&lt;认知迭代&gt;&gt; 读书笔记</span></a></div><div class="next-post pull-right"><a href="/2017/04/27/linux-command-tutorial2/"><span>linux命令学习笔记2 文件及目录管理</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '283805975f91ba7e56c7',
  clientSecret: '4958d7378aa5642a6b6fbd491315503e14da6968',
  repo: 'sizheree.github.io',
  owner: 'SizheRee',
  admin: 'SizheRee',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2019 By SizheRee</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>